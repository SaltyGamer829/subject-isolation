{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Preprocess image (resize, normalize)\n",
    "IMG_SIZE = (256, 256)\n",
    "NUM_CLASSES = 21 # 20 classes + the background\n",
    "\n",
    "# Transformation class\n",
    "class VOCTransforms:\n",
    "    def __init__(self, img_size, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(img_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "        self.target_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.long, scale=False),\n",
    "        ])\n",
    "    def __call__(self, img, target):\n",
    "        image = self.transform(img)\n",
    "        target = self.target_transform(target)\n",
    "        target = target.squeeze(0)\n",
    "        return image, target\n",
    "\n",
    "# Load dataset, image and segmentation mask\n",
    "\n",
    "voc_transforms = VOCTransforms(IMG_SIZE)\n",
    "\n",
    "DATA_ROOT = '/Users/path/to/project/directory/data'\n",
    "\n",
    "train_dataset = VOCSegmentation(\n",
    "    root=DATA_ROOT,\n",
    "    year='2012',\n",
    "    image_set='train',\n",
    "    download=False,\n",
    "    transforms=voc_transforms\n",
    ")\n",
    "\n",
    "val_dataset = VOCSegmentation(\n",
    "    root=DATA_ROOT,\n",
    "    year='2012',\n",
    "    image_set='val',\n",
    "    download=False,\n",
    "    transforms=voc_transforms\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# Had to set num_workers to 0 for VOCTransforms parallel error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define FCN model:\n",
    "    # Use convolutional layers to extract features\n",
    "    # Replace fully connected layers with 1x1 convolutions\n",
    "    # Upsample with transpose convolutions or bilinear upsampling\n",
    "\n",
    "# Forward pass image through FCN â†’ get pixel-wise class scores\n",
    "# Compute loss with segmentation mask (e.g., cross-entropy)\n",
    "# Backpropagate and update weights\n",
    "\n",
    "# After training, use FCN to predict segmentation map for new images"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
