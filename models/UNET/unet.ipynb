{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Preprocess image (resize, normalize)\n",
    "IMG_SIZE = (256, 256)\n",
    "NUM_CLASSES = 21 # 20 classes + the background\n",
    "\n",
    "# Transformation class\n",
    "class VOCTransforms:\n",
    "    def __init__(self, img_size, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(img_size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.float32, scale=True),\n",
    "            transforms.Normalize(mean=mean, std=std),\n",
    "        ])\n",
    "        self.target_transform = transforms.Compose([\n",
    "            transforms.Resize(img_size, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            transforms.ToImage(),\n",
    "            transforms.ToDtype(torch.long, scale=False),\n",
    "        ])\n",
    "    def __call__(self, img, target):\n",
    "        image = self.transform(img)\n",
    "        target = self.target_transform(target)\n",
    "        target = target.squeeze(0)\n",
    "        return image, target\n",
    "\n",
    "# Load dataset, image and segmentation mask\n",
    "\n",
    "voc_transforms = VOCTransforms(IMG_SIZE)\n",
    "\n",
    "DATA_ROOT = '/data'\n",
    "\n",
    "train_dataset = VOCSegmentation(\n",
    "    root=DATA_ROOT,\n",
    "    year='2012',\n",
    "    image_set='train',\n",
    "    download=False,\n",
    "    transforms=voc_transforms\n",
    ")\n",
    "\n",
    "val_dataset = VOCSegmentation(\n",
    "    root=DATA_ROOT,\n",
    "    year='2012',\n",
    "    image_set='val',\n",
    "    download=False,\n",
    "    transforms=voc_transforms\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4 \n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4 \n",
    ")\n",
    "\n",
    "\n",
    "# Define U-Net model:\n",
    "    # Encoder path (downsampling):\n",
    "        # conv → relu → conv → relu → maxpool\n",
    "        # repeat, doubling channels\n",
    "\n",
    "    # Decoder path (upsampling):\n",
    "        # upsample → concat with encoder feature map → convs\n",
    "        # repeat, halving channels\n",
    "\n",
    "    # Final 1x1 conv → class scores for each pixel\n",
    "\n",
    "# Forward pass → compute loss → backprop → update\n",
    "\n",
    "# Use trained model to predict segmentation masks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
